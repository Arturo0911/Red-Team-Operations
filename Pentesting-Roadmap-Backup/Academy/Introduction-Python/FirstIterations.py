#!/usr/bin/python3

import click
import requests
from pwn import *
import re
from bs4 import BeautifulSoup
from typing import (
    Dict,
    List
)


def get_html_of(url) -> str:
    p1 = log.progress("First implementation")
    response = requests.get(url=url)

    p1.status("Getting the staatus bar")

    if response.status_code != 200:
        print(f'HTTP status code of {response.status_code} returned, but 200 was expected. Exiting.')
        exit(1)

    return response.content.decode()


def count_ocurrences_in(word_list, min_length: int) -> Dict[str, int]:

    word_count = dict()

    for word in word_list:
        if len(word) < min_length:
            continue
        if word not in word_count:
            word_count[word] = 1
        else:
            current_count = word_count.get(word)
            word_count[word] = current_count + 1

    return word_count


def get_all_words_from(url: str):    
    html_page = get_html_of(url)
    soup = BeautifulSoup(html_page, "html.parser")
    raw_text = soup.get_text()

    return re.findall(r'\w+', raw_text)

def get_top_words_from(all_words, min_length: int):
    occurrences = count_ocurrences_in(all_words, min_length)
    return sorted(occurrences.items(), key=lambda item: item[1], reverse=True)
    


@click.command()
@click.option('--url', '-u', prompt='Web URL', help='URL of webpage to extract from.')
@click.option('--length', '-l', default=0, help='Minimum word length (default 0 no limit).')
def main(url, length):
    all_words = get_all_words_from(url)
    top_words = get_top_words_from(all_words, length)

    for i in range(10):
        print(top_words[i][0])


if __name__ == "__main__":
    main()
